import os
import time
import streamlit as st
from pymilvus import connections, utility, Collection, CollectionSchema, FieldSchema, DataType
from sentence_transformers import SentenceTransformer, CrossEncoder
from sklearn.preprocessing import normalize
import numpy as np

from config import (
    DATA_FILE,
    EMBEDDING_MODEL_NAME,
    GENERATION_MODEL_NAME,
    TOP_K,
    MAX_ARTICLES_TO_INDEX,
    COLLECTION_NAME,
    EMBEDDING_DIM,
    INDEX_TYPE,
    INDEX_PARAMS,
    INDEX_METRIC_TYPE,
    SEARCH_PARAMS,
    id_to_doc_map
)
from data_utils import load_data
from models import load_embedding_model, load_generation_model
from milvus_utils import (
    init_milvus_connection,
    get_or_create_collection,
    index_data_if_needed
)
from rag_core import generate_answer

# --- ç¯å¢ƒ & UI è®¾ç½® ---
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
os.environ['HF_HOME']     = './hf_cache'
st.set_page_config(layout="wide")
st.title("ğŸ“„ åŒ»ç–— RAG ç³»ç»Ÿ with Iterative Feedback")
st.markdown(f"**Embedding æ¨¡å‹:** {EMBEDDING_MODEL_NAME}  â€¢  **Generation æ¨¡å‹:** {GENERATION_MODEL_NAME}  â€¢  **Reranker:** cross-encoder/ms-marco-MiniLM-L-6-v2")

# --- 1. è¿æ¥ Milvus & å‡†å¤‡ Collection ---
alias = init_milvus_connection(host="localhost", port="19530")
collection = get_or_create_collection(
    alias=alias,
    collection_name=COLLECTION_NAME,
    embedding_dim=EMBEDDING_DIM,
    index_type=INDEX_TYPE,
    index_params=INDEX_PARAMS,
    index_metric_type=INDEX_METRIC_TYPE
)

# --- 2. åŠ è½½æ¨¡å‹ ---
embedding_model   = load_embedding_model(EMBEDDING_MODEL_NAME)
generation_model, tokenizer = load_generation_model(GENERATION_MODEL_NAME)

@st.cache_resource
def load_reranker():
    return CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")
reranker = load_reranker()

# --- 3. ç´¢å¼•æ•°æ®ï¼ˆå¦‚æœ‰å¿…è¦ï¼‰ ---
data = load_data(DATA_FILE)
index_data_if_needed(
    collection=collection,
    data=data,
    embedding_model=embedding_model,
    max_articles=MAX_ARTICLES_TO_INDEX
)

st.divider()

# --- 4. Graph-Augmented æ£€ç´¢ + Reranking ---
def search_with_reranking(query: str,
                      top_n: int = 50,
                      hops: int = 1,
                      per_hop: int = 10,
                      final_k: int = TOP_K):
    # ç¬¬ä¸€é˜¶æ®µï¼šMilvus å‘é‡å¬å› top_n
    st.info("é˜¶æ®µ1ï¼šå‘é‡å¬å›ä¸­â€¦")
    q_emb = embedding_model.encode([query])[0]
    q_emb = normalize([q_emb], norm='l2')[0]
    res1 = collection.search(
        data=[q_emb],
        anns_field="embedding",
        param={"metric_type": "IP", **SEARCH_PARAMS},
        limit=top_n,
        output_fields=["id"]
    )
    if not res1 or not res1[0]:
        return [], [], []
    cand = { hit.entity.get("id") for hit in res1[0] }
    milvus_scores = { hit.entity.get("id"): hit.distance for hit in res1[0] }

    # ç¬¬äºŒé˜¶æ®µï¼šæ–‡æ¡£â€“æ–‡æ¡£â€œå›¾â€æ‰©å±•ï¼ˆhops è·³ï¼‰
    st.info(f"é˜¶æ®µ2ï¼šå›¾æ‰©å±• {hops} è·³ï¼Œæ¯è·³ top {per_hop}â€¦")
    frontier = list(cand)
    for _ in range(hops):
        new_front = []
        for did in frontier:
            # ç”¨æ–‡æ¡£æœ¬èº« embedding å» Milvus æœ neighbors
            doc_emb = embedding_model.encode([ id_to_doc_map[did]["content"] ])[0]
            doc_emb = normalize([doc_emb], norm='l2')[0]
            neigh = collection.search(
                data=[doc_emb],
                anns_field="embedding",
                param={"metric_type": "IP", **SEARCH_PARAMS},
                limit=per_hop,
                output_fields=["id"]
            )
            for hit in neigh[0]:
                nid = hit.entity.get("id")
                if nid not in cand:
                    cand.add(nid)
                    milvus_scores[nid] = hit.distance
                    new_front.append(nid)
        frontier = new_front

    cand_ids = list(cand)
    # å‡†å¤‡ Cross-Encoder äºŒé˜¶æ®µæ’åºå¯¹
    st.info("é˜¶æ®µ3ï¼šCross-Encoder Rerankâ€¦")
    pairs = [(query, id_to_doc_map[_id]["content"]) for _id in cand_ids]
    rerank_scores = reranker.predict(pairs, convert_to_numpy=True)

    # å– final_k
    idxs = np.argsort(-rerank_scores)[:final_k]
    final_ids    = [cand_ids[i]     for i in idxs]
    final_scores = [float(rerank_scores[i]) for i in idxs]
    final_milvus = [milvus_scores[final_ids[i]] for i in range(len(final_ids))]

    return final_ids, final_milvus, final_scores

# --- 5. ä¼šè¯çŠ¶æ€ ---
if "round" not in st.session_state:
    st.session_state.round = 1
    st.session_state.history = []
    st.session_state.done = False
    st.session_state.await_feedback = False

def run_one_round(query):
    st.session_state.history.append(query)
    full_query = "ï¼›".join(st.session_state.history)  # æˆ– "\n".join(...) æ›´è‡ªç„¶
    ids, dists, reranks = search_with_reranking(full_query)

    if not ids:
        st.warning("æœªæ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£ã€‚")
        return

    st.success(f"ç¬¬ {st.session_state.round} è½®æ£€ç´¢å®Œæˆï¼Œå±•ç¤ºç»“æœå¦‚ä¸‹ï¼š")
    for i, (doc_id, d, r) in enumerate(zip(ids, dists, reranks), start=1):
        doc = id_to_doc_map.get(doc_id, {})
        title = doc.get("title", "æ— æ ‡é¢˜")
        with st.expander(f"{i}. {title}  â€¢  Milvusè·: {d:.4f}  â€¢  Rerankå¾—åˆ†: {r:.4f}"):
            st.write(doc.get("abstract", ""))
    st.info("æ­£åœ¨ç”Ÿæˆç­”æ¡ˆâ€¦")
    contexts = [id_to_doc_map[i] for i in ids]
    answer = generate_answer(full_query, contexts, generation_model, tokenizer)
    st.subheader("ğŸ“ å›ç­”")
    st.write(answer)

# --- 6. å¤šè½®äº¤äº’ UI ---
if not st.session_state.done:
    label = f"ç¬¬ {st.session_state.round} è½®ï¼Œè¯·è¾“å…¥æ‚¨çš„é—®é¢˜"
    if st.session_state.round > 1:
        st.markdown(f"å†å²è¾“å…¥ï¼š{' â” '.join(st.session_state.history)}")
    user_input = st.text_input(label, key=f"q{st.session_state.round}")

    col1, col2 = st.columns(2)
    with col1:
        if st.button("æäº¤æ£€ç´¢", key=f"submit{st.session_state.round}"):
            if user_input.strip():
                run_one_round(user_input.strip())
                if st.session_state.round < 3:
                    st.session_state.await_feedback = True
                else:
                    st.success("å·²è¾¾åˆ°ä¸‰è½®ä¸Šé™ï¼Œç»“æŸä¼šè¯ã€‚")
                    st.session_state.done = True

    if st.session_state.await_feedback:
        with col2:
            if st.button("æ»¡æ„ï¼Œç»“æŸ", key=f"sat{st.session_state.round}"):
                st.success("æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼Œä¼šè¯ç»“æŸã€‚")
                st.session_state.done = True
                st.session_state.await_feedback = False
            if st.button("ä¸æ»¡æ„ï¼Œç»§ç»­", key=f"unsat{st.session_state.round}"):
                st.session_state.round += 1
                st.session_state.await_feedback = False
                st.rerun()

# --- 7. ä¾§è¾¹æ é…ç½®ä¿¡æ¯ ---
st.sidebar.header("ç³»ç»Ÿé…ç½®")
st.sidebar.markdown(f"- å‘é‡å­˜å‚¨ï¼šMilvus Standalone")
st.sidebar.markdown(f"- Collectionï¼š{COLLECTION_NAME}")
st.sidebar.markdown(f"- æ•°æ®æ–‡ä»¶ï¼š{DATA_FILE}")
st.sidebar.markdown(f"- æœ€å¤§ç´¢å¼•æ•°ï¼š{MAX_ARTICLES_TO_INDEX}")
st.sidebar.markdown(f"- æ£€ç´¢ Top Kï¼š{TOP_K}")
st.sidebar.markdown(f"- ä¸€é˜¶æ®µå¬å› top_nï¼š50")
st.sidebar.markdown(f"- äºŒé˜¶æ®µ Rerankerï¼šcross-encoder/ms-marco-MiniLM-L-6-v2")